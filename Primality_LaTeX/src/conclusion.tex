\section{Conclusions}
%We didn't conclude anything just yet. %TODO

%For small numbers, simple techniques like trial division seem to work well.
%For big numbers, probablistic method seems to perform better.

As we see the Trial Divion and Wheel Sieve algorithm perform well for small data, but for big numbers they are exponential in the input size.
They do have an error rate of $0\%$.
For bigger data SS and MR perform better.
MR seems to outperform SS both in runtime and in error rate.
However for the runtime this might depend on how we implemented those since both have the same time complexity.
Although AKS would theoretically run in polynomial time, it really is the snail of the bunch and therefore it has been decided to drop the results for integers above $2^13$.

Something else that looks interesting is that the error is low for both small inputs and large inputs.
For small inputs, it's probably that there are more random numbers for which the SS and MR tests succeed.
For large inputs the error is probably small, because for larger numbers, primes get more rare and it is more likely that the algorithm is being tested on a lot of composite numbers.
